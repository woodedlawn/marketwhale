{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8db3dd3",
   "metadata": {},
   "source": [
    "# Marketwhale\n",
    "\n",
    "* Our company is focused on researching and creating accurate trading algorithms for crypto currency using machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import hvplot.pandas\n",
    "from finta import TA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, schedules, SGD\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from finta import TA\n",
    "from datetime import datetime\n",
    "import math\n",
    "import holoviews as hv\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0730f5b",
   "metadata": {},
   "source": [
    "# Part 1: Algorithmic Trading- SVM Model \n",
    "### Completed by Rodrigo Monge\n",
    "**  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d910101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file by calling the load_dotenv function\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free Crypto API Call endpoint URLs for the held cryptocurrency assets\n",
    "btc_url = \"https://api.alternative.me/v2/ticker/Bitcoin/?convert=USD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Python requests library, make an API call to access the current price of BTC\n",
    "btc_response = requests.get(btc_url).json()\n",
    "\n",
    "# json.dumps function to review the response data from the API call\n",
    "# Indent and sort_keys parameters to make the response object readable\n",
    "print(json.dumps(\n",
    "    btc_response,\n",
    "    indent=4,\n",
    "    sort_keys=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f386b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate the BTC response object to access the current price of BTC\n",
    "btc_price = btc_response[\"data\"]['1'][\"quotes\"][\"USD\"][\"price\"]\n",
    "\n",
    "# Print the current price of BTC\n",
    "print(f\"The current price for Bitcoin is ${btc_price:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use yfinance to retrieve BTC close values (note that with the current API 1m data can only be done for 7 days, and 1 hour only for 730 days)\n",
    "start = \"2020-10-30\"\n",
    "end = \"2021-10-14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a87f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use yfinance to retrieve BTC (hourly data)\n",
    "btc_df = yf.download(\n",
    "    \"BTC-USD\",\n",
    "    start=start,\n",
    "    end=end,\n",
    "    interval=\"1h\"\n",
    ")\n",
    "\n",
    "btc_df= btc_df.rename(columns=str.lower)\n",
    "btc_df= btc_df.drop(['volume','adj close'], axis=1)\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df.loc[:,['close']].hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fdb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Python requests library, make an API call to access the current fear and greed index (indicator of sentiment, used for volatility)\n",
    "fear_and_greed_url = \"https://api.alternative.me/fng/?limit=350\"\n",
    "\n",
    "fear_and_greed_response = requests.get(fear_and_greed_url).json()\n",
    "\n",
    "fear_greed_df = pd.DataFrame(fear_and_greed_response[\"data\"])\n",
    "\n",
    "fear_greed_df['timestamp'] = pd.to_datetime(fear_greed_df['timestamp'], unit='s')\n",
    "\n",
    "fear_greed_df = fear_greed_df.set_index('timestamp').drop(['time_until_update', 'value_classification'], axis=1)\n",
    "\n",
    "display(fear_greed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b825bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the columns\n",
    "\n",
    "btc_df_new = btc_df.reset_index()\n",
    "btc_df_new['Dates'] = pd.to_datetime(btc_df_new['index']).dt.date\n",
    "btc_df_new['Time'] = pd.to_datetime(btc_df_new['index']).dt.time\n",
    "btc_df_new = btc_df_new.set_index(\"Dates\")\n",
    "btc_df_new = pd.merge(btc_df_new, fear_greed_df, left_index=True, right_index=True)\n",
    "btc_df_new = btc_df_new.reset_index()\n",
    "btc_df_new = btc_df_new.drop(['level_0', 'Time'], axis=1)\n",
    "btc_df_new = btc_df_new.set_index(\"index\")\n",
    "btc_df_new.rename({'value': 'fear_greed'}, axis=1, inplace=True)\n",
    "btc_df = btc_df_new\n",
    "\n",
    "display(btc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb003eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add SMA to our data, long and short to be verified\n",
    "\n",
    "sma_short = 20\n",
    "sma_long = 100\n",
    "\n",
    "SMA20 = TA.SMA(btc_df, sma_short)\n",
    "SMA100 = TA.SMA(btc_df, sma_long)\n",
    "\n",
    "btc_df[\"SMA20\"]=SMA20\n",
    "btc_df[\"SMA100\"]=SMA100\n",
    "\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column to hold the trading signal\n",
    "btc_df[\"SMA Signal\"] = 0.0\n",
    "\n",
    "# Generate the trading signal 0 or 1,\n",
    "# where 1 is the short-window (SMA20) greater than the long-window (SMA100)\n",
    "# and 0 is when the condition is not met\n",
    "btc_df['SMA Signal'] = np.where((btc_df['SMA20'] < btc_df['SMA100']),\n",
    "                            1.0, 0.0)\n",
    "# Review the DataFrame\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the points in time when the Signal value changes\n",
    "# Identify trade entry (1) and exit (-1) points\n",
    "btc_df[\"SMA Entry/Exit\"] = btc_df[\"SMA Signal\"].diff()\n",
    "\n",
    "# Review the DataFrame\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize moving averages\n",
    "moving_avgs = btc_df[['SMA20', 'SMA100', 'close']].hvplot(\n",
    "    ylabel='Price in $',\n",
    "    width=1000,\n",
    "    height=400)\n",
    "\n",
    "# Show the plot\n",
    "moving_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb98d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize exit position relative to close price\n",
    "exit = btc_df[btc_df['SMA Entry/Exit'] == -1.0]['close'].hvplot.scatter(\n",
    "    color='blue',\n",
    "    marker='v',\n",
    "    legend=False,\n",
    "    ylabel='Price in $',\n",
    "    width=1000,\n",
    "    height=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize entry position relative to close price\n",
    "entry = btc_df[btc_df['SMA Entry/Exit'] == 1.0]['close'].hvplot.scatter(\n",
    "    color='limegreen',\n",
    "     marker='^',\n",
    "    legend=False,\n",
    "    ylabel='Price in $',\n",
    "    width=1000,\n",
    "    height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91779e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize close price for the investment\n",
    "security_close = btc_df[['close']].hvplot(\n",
    "    line_color='lightgray',\n",
    "    ylabel='Price in $',\n",
    "    width=1000,\n",
    "    height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e66103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize moving averages\n",
    "moving_avgs = btc_df[['SMA20', 'SMA100']].hvplot(\n",
    "    ylabel='Price in $',\n",
    "    width=1000,\n",
    "    height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the overlay plot\n",
    "entry_exit_plot = security_close * moving_avgs * entry * exit\n",
    "\n",
    "# Show the plot\n",
    "entry_exit_plot.opts(\n",
    "    title=\"BTC - SMA20, SMA100, Entry and Exit Points\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add Bollinger Bands Width to our data\n",
    "\n",
    "BBWIDTH = TA.BBWIDTH(btc_df)\n",
    "\n",
    "btc_df[\"BBWIDTH\"]=BBWIDTH\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add WMA to our data\n",
    "\n",
    "WMA = TA.WMA(btc_df)\n",
    "\n",
    "btc_df[\"WMA\"]=WMA\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily returns using the closing prices and the pct_change function\n",
    "btc_df[\"actual_returns\"] = btc_df[\"close\"].pct_change()\n",
    "btc_df = btc_df.dropna()\n",
    "\n",
    "# Display sample data\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e61a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for actual returns signals\n",
    "btc_df['actual returns signal'] = 0.0\n",
    "\n",
    "# Create the signal to buy\n",
    "btc_df['actual returns signal'] = np.where((btc_df['actual_returns'] < 0),\n",
    "                            -1.0, 1.0)\n",
    "\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8da054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the points in time when the Signal value changes\n",
    "# Identify trade entry (1) and exit (-1) points\n",
    "btc_df[\"actual returns Entry/Exit\"] = btc_df[\"actual returns signal\"].diff()\n",
    "\n",
    "# Review the DataFrame\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a copy of the `sma_fast` and `sma_slow` columns to a new DataFrame called `X`\n",
    "X_btc = btc_df[['close','fear_greed','WMA','BBWIDTH','SMA20','SMA100',\"WMA\"]].shift().dropna().copy()\n",
    "\n",
    "# Display sample data\n",
    "display(X_btc.head())\n",
    "display(X_btc.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the new \"signal\" column to a new Series called `y`.\n",
    "\n",
    "y_btc = btc_df['actual returns signal'].dropna().copy()\n",
    "\n",
    "display(y_btc.head())\n",
    "display(y_btc.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f85c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X_btc.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)\n",
    "\n",
    "# Select the ending period for the training data with an offset of 7 months\n",
    "training_end = X_btc.index.min() + DateOffset(months=7)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad989d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_btc_train = X_btc.loc[training_begin:training_end]\n",
    "y_btc_train = y_btc.loc[training_begin:training_end]\n",
    "\n",
    "# Display sample data\n",
    "display(X_btc_train.head())\n",
    "display(y_btc_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_btc_test = X_btc.loc[training_end:]\n",
    "y_btc_test = y_btc.loc[training_end:]\n",
    "\n",
    "# Display sample data\n",
    "display(X_btc_test.head())\n",
    "display(y_btc_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X_train data\n",
    "X_btc_scaler = scaler.fit(X_btc_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_btc_train_scaled = X_btc_scaler.transform(X_btc_train)\n",
    "X_btc_test_scaled = X_btc_scaler.transform(X_btc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier model\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# Fit the model to the data using X_train_scaled and y_train\n",
    "svm_model = svm_model.fit(X_btc_train_scaled, y_btc_train)\n",
    "\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "training_signal_predictions = svm_model.predict(X_btc_train_scaled)\n",
    "\n",
    "# Display the sample predictions\n",
    "training_signal_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using a classification report\n",
    "training_report = classification_report(y_btc_train, training_signal_predictions)\n",
    "print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f144b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict the trading signals for the testing data.\n",
    "testing_signal_predictions = svm_model.predict(X_btc_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405474e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report = classification_report(y_btc_test, testing_signal_predictions)\n",
    "print(testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ccf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_btc_test.index)\n",
    "\n",
    "predictions_df[\"predicted_signal\"] = testing_signal_predictions\n",
    "\n",
    "predictions_df[\"actual_returns\"] = btc_df[\"actual_returns\"]\n",
    "\n",
    "predictions_df[\"trading_algorithm_returns\"] = (\n",
    "    predictions_df[\"actual_returns\"] * predictions_df[\"predicted_signal\"]\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "predictions_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623db638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + predictions_df[[\"actual_returns\", \"trading_algorithm_returns\"]]).cumprod().hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db63127",
   "metadata": {},
   "source": [
    "# Part 2: Neural Network - LSTM Model\n",
    "### Completed by Jonathan Woolsey\n",
    "** **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model is without fear and greed index \n",
    "#Use yfinance to retrieve BTC and ETH close values (note that with the current API 1m data can only be done for 7 days, and 1 hour only for 730 days)\n",
    "\n",
    "start = \"2020-10-30\"\n",
    "end = \"2021-10-14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use yfinance to retrieve BTC and ETH close values\n",
    "btc_df = yf.download(\n",
    "    \"BTC-USD\",\n",
    "    start=start,\n",
    "    end=end,\n",
    "    interval=\"1h\"\n",
    ")\n",
    "\n",
    "btc_df= btc_df.rename(columns=str.lower)\n",
    "btc_df= btc_df.drop(['volume','adj close'], axis=1)\n",
    "\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some TA\n",
    "sma_short = 20\n",
    "sma_long = 100\n",
    "\n",
    "btc_df[\"SMA20\"] = TA.SMA(btc_df, sma_short)\n",
    "btc_df[\"SMA100\"] = TA.SMA(btc_df, sma_long)\n",
    "btc_df[\"WMA\"] = TA.WMA(btc_df)\n",
    "\n",
    "btc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily returns using the closing prices and the pct_change function\n",
    "btc_df[\"actual_returns\"] = btc_df[\"close\"].pct_change()\n",
    "btc_df.dropna(inplace=True)\n",
    "\n",
    "# Display sample data\n",
    "display(btc_df.head())\n",
    "display(btc_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for actual returns signals\n",
    "btc_df['actual returns signal'] = 0.0\n",
    "\n",
    "# When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "btc_df.loc[(btc_df['actual_returns'] >= 0), 'actual returns signal'] = 1\n",
    "\n",
    "# When Actual Returns are less than 0, generate signal to sell stock short\n",
    "btc_df.loc[(btc_df['actual_returns'] < 0), 'actual returns signal'] = -1\n",
    "\n",
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features (X) and target (y) sets\n",
    "y = btc_df['actual returns signal'].dropna().copy().replace(-1, 0)\n",
    "display(y.value_counts())\n",
    "\n",
    "X = btc_df[['close','WMA','SMA20','SMA100']].shift().dropna().copy()\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea36eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "training_period_months = 6\n",
    "training_end = X.index.min() + DateOffset(months=training_period_months)\n",
    "\n",
    "# Display the training begin / end dates\n",
    "print(training_begin)\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6bb660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()\n",
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features DataFrames\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "number_output_neurons = 1\n",
    "number_input_features = X.shape[1]\n",
    "\n",
    "hidden_nodes_layer1 = math.floor((number_input_features + number_output_neurons) / 2)\n",
    "hidden_nodes_layer2 = math.floor((hidden_nodes_layer1 + number_output_neurons) / 2)\n",
    "\n",
    "X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a7a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "\n",
    "# add LSTM layer\n",
    "nn.add(LSTM(10, input_shape=(1, number_input_features), return_sequences=True))\n",
    "nn.add(Flatten())\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(Dense(units=number_output_neurons, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fbfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model = nn.fit(X_train_reshaped, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_reshaped, y_test, verbose=2)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print()\n",
    "print(f\"Loss: {model_loss}\")\n",
    "print(f\"Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as JSON - model will be backtested\n",
    "if not os.path.exists('Models'):\n",
    "  os.makedirs('Models')\n",
    "\n",
    "def save_model_weights(nn, name):\n",
    "  nn_json = nn.to_json()\n",
    "  file_path = Path(f\"Models/{name}.json\")\n",
    "  with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(nn_json)\n",
    "  nn.save_weights(f\"Models/{name}.h5\")\n",
    "\n",
    "def load_model_weights(name):\n",
    "  file_path = Path(f\"Models/{name}.json\")\n",
    "  with open(file_path, \"r\") as json_file:\n",
    "      model_json = json_file.read()\n",
    "  loaded_model = model_from_json(model_json)\n",
    "  loaded_model.load_weights(f\"Models/{name}.h5\")\n",
    "  return loaded_model\n",
    "\n",
    "save_model_weights(nn, 'model_lstm')\n",
    "\n",
    "nn_loaded = load_model_weights('model_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55411776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions = nn_loaded.predict(X_test_reshaped)\n",
    "\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "predictions_df[\"predicted_signal\"] = np.where(predictions > 0.5, 1, -1 )\n",
    "\n",
    "predictions_df[\"actual_returns\"] = btc_df[\"actual_returns\"]\n",
    "\n",
    "predictions_df[\"trading_algorithm_returns\"] = (\n",
    "    predictions_df[\"actual_returns\"] * predictions_df[\"predicted_signal\"]\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "display(predictions_df[\"predicted_signal\"].value_counts())\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b26ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + predictions_df[[\"actual_returns\", \"trading_algorithm_returns\"]]).cumprod().hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef4e9c",
   "metadata": {},
   "source": [
    "# Part 3: Neural Network - CNN Model\n",
    "### Completed by Jonathan Woolsey\n",
    "** **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc7b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model is without fear/greed index\n",
    "#split a data into samples\n",
    "# code below borrowed from https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/\n",
    "\n",
    "def split_data(df, n_steps):\n",
    "  X, y = list(), list()\n",
    "  for i in range(len(df)):\n",
    "    # find the end of this pattern\n",
    "    end_ix = i + n_steps\n",
    "    # check if we are beyond the sequence\n",
    "    if end_ix > len(df)-1:\n",
    "      break\n",
    "    # gather input and output parts of the pattern\n",
    "    seq_x, seq_y = df[['close','WMA','SMA20','SMA100']][i:end_ix], df['actual returns signal'][end_ix]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "  return np.array(X), np.array(y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features (X) and target (y) sets\n",
    "feature_cols = ['close','WMA','SMA20','SMA100']\n",
    "prepped_df = btc_df[feature_cols + ['actual returns signal']].dropna().copy()\n",
    "prepped_df['actual returns signal'] = btc_df['actual returns signal'].dropna().copy().replace(-1, 0)\n",
    "prepped_df[feature_cols] = btc_df[feature_cols].shift()\n",
    "prepped_df.dropna(inplace=True)\n",
    "\n",
    "display(prepped_df.head())\n",
    "\n",
    "n_steps = 6\n",
    "n_features = 4\n",
    "\n",
    "X, y = split_data(prepped_df, n_steps)\n",
    "display(len(X))\n",
    "display(len(y))\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c95be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = .5\n",
    "train_samples = math.floor(len(X) * train_percent)\n",
    "X_train, X_test = X[:train_samples], X[train_samples + 1:]\n",
    "y_train, y_test = y[:train_samples], y[train_samples + 1:]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features DataFrames\n",
    "\n",
    "# You'll have to fit and store a scaler for each channel\n",
    "# https://stackoverflow.com/questions/50125844/how-to-standard-scale-a-3d-matrix\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
    "\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de401989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "number_output_neurons = 1\n",
    "number_input_features = n_features\n",
    "\n",
    "hidden_nodes_layer1 = math.floor((number_input_features + number_output_neurons) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74591df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "\n",
    "nn.add(Conv1D(filters=10, kernel_size=3, activation='relu', input_shape=(n_steps, n_features)))\n",
    "nn.add(MaxPooling1D(pool_size=2))\n",
    "nn.add(Flatten())\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e53e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model = nn.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as JSON - model will be backtested\n",
    "if not os.path.exists('Models'):\n",
    "  os.makedirs('Models')\n",
    "\n",
    "def save_model_weights(nn, name):\n",
    "  nn_json = nn.to_json()\n",
    "  file_path = Path(f\"Models/{name}.json\")\n",
    "  with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(nn_json)\n",
    "  nn.save_weights(f\"Models/{name}.h5\")\n",
    "\n",
    "def load_model_weights(name):\n",
    "  file_path = Path(f\"Models/{name}.json\")\n",
    "  with open(file_path, \"r\") as json_file:\n",
    "      model_json = json_file.read()\n",
    "  loaded_model = model_from_json(model_json)\n",
    "  loaded_model.load_weights(f\"Models/{name}.h5\")\n",
    "  return loaded_model\n",
    "\n",
    "save_model_weights(nn, 'model_cnn')\n",
    "\n",
    "nn_loaded = load_model_weights('model_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbff10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions = nn_loaded.predict(X_test)\n",
    "predictions = predictions.flatten()\n",
    "predictions\n",
    "predictions_df = pd.DataFrame(index=prepped_df.iloc[(train_samples + n_steps) + 1:].index)\n",
    "\n",
    "predictions_df[\"predicted_signal\"] = np.where(predictions > 0.5, 1, -1 )\n",
    "\n",
    "predictions_df[\"actual_returns\"] = btc_df[\"actual_returns\"]\n",
    "\n",
    "predictions_df[\"trading_algorithm_returns\"] = (\n",
    "    predictions_df[\"actual_returns\"] * predictions_df[\"predicted_signal\"]\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "display(predictions_df[\"predicted_signal\"].value_counts())\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e5eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + predictions_df[[\"actual_returns\", \"trading_algorithm_returns\"]]).cumprod().hvplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
